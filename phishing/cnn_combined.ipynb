{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.12.3-py3-none-any.whl (258 kB)\n",
      "     l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/258.3 kB ? eta -:--:--━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━ 235.5/258.3 kB 7.2 MB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 258.3/258.3 kB 6.7 MB/s eta 0:00:00\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.3 in /home/ihranicky/git/domainradar-training/.venv/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/ihranicky/git/domainradar-training/.venv/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /home/ihranicky/git/domainradar-training/.venv/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (1.5.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ihranicky/git/domainradar-training/.venv/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ihranicky/git/domainradar-training/.venv/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.12.3 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm \n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils.preprocess import NDF\n",
    "from collections import Counter\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 20:10:56,965 - utils.preprocess - INFO - Benign dataset path: ../feature-extraction/floor/benign_combined.parquet\n",
      "2024-06-12 20:10:56,967 - utils.preprocess - INFO - Malign dataset path: ../feature-extraction/floor/phishing_4.parquet\n",
      "2024-06-12 20:10:57,889 - utils.preprocess - INFO - Number of records in combined dataset: 1016263\n"
     ]
    }
   ],
   "source": [
    "from utils.preprocess import NDF\n",
    "\n",
    "input_data = {\n",
    "    'benign': '../feature-extraction/floor/benign_combined.parquet',\n",
    "    #'malign': 'parkets/malware_bp.parquet'\n",
    "    #'malign': 'parkets/phishing_final_2024.parquet'\n",
    "    'malign': '../feature-extraction/floor/phishing_4.parquet'\n",
    "}\n",
    "dataset = NDF(\"cnn\", True, input_data=input_data, one_line_processing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print total number of samples\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal number of samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43mdataset\u001b[49m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(np\u001b[38;5;241m.\u001b[39marray(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m]), np\u001b[38;5;241m.\u001b[39marray(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]), test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      7\u001b[0m new_label_counts \u001b[38;5;241m=\u001b[39m Counter(y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# print total number of samples\n",
    "print(f\"Total number of samples: {len(dataset)}\")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.array(dataset['features']), np.array(dataset['labels']), test_size=0.05, random_state=42)\n",
    "\n",
    "\n",
    "new_label_counts = Counter(y_train)\n",
    "print(\"Class distribution:\")\n",
    "for label, count in new_label_counts.items():\n",
    "    print(f\"Class {label}: {count}\")\n",
    "\n",
    "\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train_smote, y_train_smote = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "# Check the new class distribution\n",
    "new_label_counts = Counter(y_train_smote)\n",
    "print(\"New class distribution after SMOTE:\")\n",
    "for label, count in new_label_counts.items():\n",
    "    print(f\"Class {label}: {count}\")\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "x_train = torch.tensor(x_train_smote, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)  # Convert x_test to tensor\n",
    "y_train = torch.tensor(y_train_smote, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long) \n",
    "feature_size = x_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# Function to calculate the next perfect square greater than a given number\n",
    "def next_perfect_square(n):\n",
    "    next_square = math.ceil(n**0.5)**2\n",
    "    return next_square\n",
    "\n",
    "feature_size = x_train.shape[1]\n",
    "desired_size = next_perfect_square(feature_size)\n",
    "side_size = int(desired_size ** 0.5)\n",
    "\n",
    "# Calculate padding required to achieve the desired size\n",
    "padding = desired_size - feature_size\n",
    "\n",
    "# Applying dynamic padding\n",
    "if padding > 0:\n",
    "    x_train_padded = F.pad(x_train, (0, padding), 'constant', 0)\n",
    "    x_test_padded = F.pad(x_test, (0, padding), 'constant', 0)\n",
    "else:\n",
    "    x_train_padded = x_train\n",
    "    x_test_padded = x_test\n",
    "\n",
    "# Reshape the data to the new dynamically calculated square shape\n",
    "x_train = x_train_padded.view(-1, 1, side_size, side_size)\n",
    "x_test = x_test_padded.view(-1, 1, side_size, side_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, side_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Adjust the size calculation based on the number of convolutional layers\n",
    "        self.fc1 = nn.Linear(128 * (side_size-6)**2, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 128)\n",
    "        self.fc4 = nn.Linear(128, 2)\n",
    "        \n",
    "        # Optionally use dropout\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        \n",
    "        print(\"CNN model created\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout1(x)  # Dropout applied after flattening\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)  # Dropout applied after first fully connected layer\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x) # No softmax here, as CrossEntropyLoss applies LogSoftmax internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model created\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     54\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 55\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Compute average loss\u001b[39;00m\n\u001b[1;32m     58\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.000238\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 15\n",
    "\n",
    "\n",
    "model = Net(side_size).to(device)  # Classic fully connected model\n",
    "\n",
    "\n",
    "#CANNOT RETURN SOFT MAX AS THE LOSS FUNCTION IS CROSS ENTROPY\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_data = TensorDataset(x_train, y_train.long())\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Function to compute accuracy and F1 score\n",
    "def compute_metrics(data_loader, model):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)  # Move data to the device\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            true_labels.extend(target.cpu().tolist())  # Move data back to CPU for scoring\n",
    "            predictions.extend(pred.view_as(target).cpu().tolist())  # Move data back to CPU\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    return accuracy, f1\n",
    "\n",
    "epoch_losses = []\n",
    "epoch_accuracies = []\n",
    "epoch_f1s = []\n",
    "\n",
    "# start timer\n",
    "import time\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    timer = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)  # Move data to the device\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Compute average loss\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    epoch_losses.append(avg_loss)\n",
    "\n",
    "    # Evaluate model and store metrics\n",
    "    train_accuracy, train_f1 = compute_metrics(train_loader, model)\n",
    "    epoch_accuracies.append(train_accuracy)\n",
    "    epoch_f1s.append(train_f1)\n",
    "\n",
    "    # Enhanced logging\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {avg_loss:.4f}, Accuracy: {train_accuracy:.4f}, F1 Score: {train_f1:.4f} Time taken: {round(time.time() - timer, 2)}s\")\n",
    "\n",
    "\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), './models/phishing_with_final_parquet.pth')\n",
    "print(\"Model training complete and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics:\n",
      "accuracy: 0.9902\n",
      "f1: 0.9902\n",
      "precision: 0.9902\n",
      "recall: 0.9902\n",
      "roc_auc_score: 0.9964\n",
      "cross_entropy_loss: 0.0475\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def compute_metrics(data_loader, model, criterion):\n",
    "    \"\"\"\n",
    "    Computes a wide range of performance metrics for the given model evaluated on the provided DataLoader.\n",
    "    \n",
    "    Parameters:\n",
    "        data_loader (DataLoader): DataLoader for evaluation data.\n",
    "        model (torch.nn.Module): The neural network model to evaluate.\n",
    "        criterion (torch.nn.Module): Loss function used for the model.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing various performance metrics.\n",
    "    \"\"\"\n",
    "    model.eval()  # Switch model to evaluation mode\n",
    "    true_labels, predictions, probs, losses = [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            prob = torch.nn.functional.softmax(output, dim=1)[:,1]  # Probability for class 1\n",
    "            true_labels.extend(target.cpu().numpy())\n",
    "            predictions.extend(pred.cpu().view_as(target).numpy())\n",
    "            probs.extend(prob.cpu().numpy())\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(true_labels, predictions),\n",
    "        'f1': f1_score(true_labels, predictions, average='weighted'),\n",
    "        'precision': precision_score(true_labels, predictions, average='weighted', zero_division=0),\n",
    "        'recall': recall_score(true_labels, predictions, average='weighted', zero_division=0),\n",
    "        'roc_auc_score': roc_auc_score(true_labels, probs) if len(np.unique(true_labels)) > 1 else 0,\n",
    "        'cross_entropy_loss': np.mean(losses),\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def evaluate_model(model, x_test, y_test, batch_size, criterion):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test dataset and prints out a comprehensive set of performance metrics.\n",
    "    \n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The neural network model to evaluate.\n",
    "        x_test (Tensor): Test dataset features.\n",
    "        y_test (Tensor): Test dataset labels.\n",
    "        batch_size (int): Batch size for data loading.\n",
    "        criterion (torch.nn.Module): Loss function used for the model.\n",
    "    \"\"\"\n",
    "    test_data = TensorDataset(x_test, y_test.long())\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "    \n",
    "    metrics = compute_metrics(test_loader, model, criterion)\n",
    "    \n",
    "    # Display the metrics\n",
    "    print(\"Test Metrics:\")\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        if metric_name == 'confusion_matrix':\n",
    "            print(f\"{metric_name}:\\n{metric_value}\\n\")\n",
    "        else:\n",
    "            print(f\"{metric_name}: {metric_value:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Assuming criterion is defined (e.g., nn.CrossEntropyLoss())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Example of how to use the evaluate_model function:\n",
    "# model = Net()  # Assume Net is defined elsewhere and is your trained model\n",
    "x_test, y_test = x_test.to(device), y_test.to(device)  # Move data to the device\n",
    "metrics = evaluate_model(model, x_test, y_test, BATCH_SIZE, criterion)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
