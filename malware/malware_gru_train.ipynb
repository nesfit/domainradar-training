{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2da08d06-be0d-468a-bd17-d7bcba74880a",
   "metadata": {},
   "source": [
    "## Columns to be removed from training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94277f7d-8c84-4e29-a892-780785afdb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "disqualified_columns = [\"tls_joint_isoitu_policy_crt_count\", \"rdap_time_from_last_change\", \"lex_www_flag\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b715b0f7",
   "metadata": {},
   "source": [
    "# Load Tensorflow and check GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a3b996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import sys\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1258a0e",
   "metadata": {},
   "source": [
    "# Load input datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069058d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas.core.dtypes import common as com\n",
    "from pyarrow import Table\n",
    "\n",
    "\n",
    "def union_tables(tables: [pa.Table]) -> pa.Table:\n",
    "    union_table = tables[0]\n",
    "    for table in tables[1:]:\n",
    "        right_not_in_union = union_table.join(right_table=table, keys='domain_name', join_type='right anti',\n",
    "                                              coalesce_keys=True, use_threads=True)\n",
    "        union_table = pa.concat_tables([union_table, right_not_in_union])\n",
    "    return union_table\n",
    "\n",
    "# #############################################################\n",
    "# EDIT this to specify benign / malicious datasets to use     #\n",
    "# #############################################################\n",
    "benign_dataset_filenames = [\n",
    "    '../feature-extraction/floor/benign_2312.parquet',\n",
    "]\n",
    "malicious_dataset_filenames = [\n",
    "    '../feature-extraction/floor/malware_2406_strict.parquet'\n",
    "]\n",
    "# #############################################################\n",
    "# EDIT this for to set appropriate labels (malware, dga, ...) #\n",
    "# #############################################################\n",
    "benign_label = \"benign\"\n",
    "malicious_label = \"phishing\"\n",
    "# #############################################################\n",
    "\n",
    "\n",
    "\n",
    "# Unify malicious datasets and benign datasets\n",
    "schema = (pq.read_table(malicious_dataset_filenames[0])).schema # Use the schema from the first malicious filename\n",
    "benign_tables = [pq.read_table(filename).cast(schema) for filename in benign_dataset_filenames]\n",
    "malicious_tables = [pq.read_table(filename).cast(schema) for filename in malicious_dataset_filenames]\n",
    "malicious = union_tables(malicious_tables)\n",
    "benign = union_tables(benign_tables)\n",
    "\n",
    "# Convert pyarrow tables to pandas dataframes\n",
    "df_benign = benign.to_pandas()\n",
    "df_malicious = malicious.to_pandas()\n",
    "\n",
    "# Set appropriate labels\n",
    "df_benign[\"label\"] = benign_label\n",
    "df_malicious[\"label\"] = malicious_label\n",
    "class_map = {benign_label: 0, malicious_label: 1}\n",
    "\n",
    "# print column count\n",
    "print(f\"Benign columns: {len(df_benign.columns)}\")\n",
    "print(f\"Malicious columns: {len(df_malicious.columns)}\")\n",
    "\n",
    "\n",
    "\n",
    "# ===================\n",
    "# AUTO BALANCING !!!\n",
    "# Subsample benign to match the size of malicious\n",
    "# df_benign = df_benign.sample(n=len(df_malicious))\n",
    "# ===================\n",
    "\n",
    "# Concatentate benign and malicious\n",
    "df = pd.concat([df_benign, df_malicious])\n",
    "\n",
    "\n",
    "def cast_timestamp(df: DataFrame):\n",
    "    \"\"\"\n",
    "    Cast timestamp fields to seconds since epoch.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if com.is_timedelta64_dtype(df[col]):\n",
    "            df[col] = df[col].dt.total_seconds()  # This converts timedelta to float (seconds)\n",
    "        elif com.is_datetime64_any_dtype(df[col]):\n",
    "            df[col] = df[col].astype(np.int64) // 10**9  # Converts datetime64 to Unix timestamp (seconds)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = cast_timestamp(df)\n",
    "\n",
    "# Handle NaNs\n",
    "df.fillna(-1, inplace=True)\n",
    "\n",
    "\n",
    "# SUBSAMPLE (OPTIONAL)\n",
    "subsample = 1.0 # 1.0 means no subsample\n",
    "if subsample < 1.0:\n",
    "    df = df.sample(frac=subsample)\n",
    "\n",
    "# Drop the domain name column\n",
    "df.drop(\"domain_name\", axis=1, inplace=True)\n",
    "\n",
    "# Remove disqualified columns\n",
    "for column in disqualified_columns:\n",
    "    if column in df.columns:\n",
    "        df.drop(column, axis=1, inplace=True)\n",
    "\n",
    "labels = df['label'].apply(lambda x: class_map[x]) # y vector\n",
    "features = df.drop('label', axis=1).copy() # X matrix\n",
    "\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Benign count: {len(df_benign)}\")\n",
    "print(f\"Malicious count: {len(df_malicious)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e103a79",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87705691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    " \n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(features)\n",
    "features = pd.DataFrame(scaled_data, columns=features.columns)\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, \"boundaries/malware_gru_scaler.joblib\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5fd630",
   "metadata": {},
   "source": [
    "# Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4bf762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "  features,\n",
    "  labels,\n",
    "  test_size=0.1,\n",
    "  random_state=42,\n",
    "  shuffle=True, \n",
    "  stratify=labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fecd4d4",
   "metadata": {},
   "source": [
    "# Define the NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ecaeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, feature_size: int, embedding_dim: int=3):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # Embedding layer for domain parts, handling missing values with a special index\n",
    "        self.embedding = nn.Embedding(feature_size + 1, embedding_dim, padding_idx=feature_size)\n",
    "\n",
    "        # 1D Convolutional layer to capture local dependencies\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, 64, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv1d(64, feature_size, kernel_size=3, padding=1)\n",
    "\n",
    "        # GRU layer to capture long-term dependencies\n",
    "        self.gru = nn.GRU(feature_size, 64, batch_first=True, bidirectional=False)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64, 1024)  # Adjusted to accommodate bidirectional GRU output\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 128)\n",
    "        self.fc4 = nn.Linear(128, 1)  # Output layer for binary classification\n",
    "\n",
    "        # Dropout and Batch Normalization\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(feature_size)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(1024)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convert input to long if it's not already\n",
    "        x = x.long()\n",
    "\n",
    "        # Embedding input\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 2, 1)  # Rearrange dimensions for Conv1D\n",
    "\n",
    "        # Convolutional layers with Batch Norm and ReLU activations\n",
    "        x = F.relu(self.batchnorm1(self.conv1(x)))\n",
    "        x = F.relu(self.batchnorm2(self.conv2(x)))\n",
    "\n",
    "        # GRU layer\n",
    "        x, _ = self.gru(x)\n",
    "        x = torch.mean(x, dim=1)  # Global average pooling over sequence\n",
    "\n",
    "        # Fully connected layers with Dropout and Batch Norm\n",
    "        x = self.dropout(F.relu(self.batchnorm3(self.fc1(x))))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "\n",
    "        # Sigmoid activation for binary classification\n",
    "        #x = torch.sigmoid(self.fc4(x))\n",
    "\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e39b63c-49a3-43f1-a1a9-b0a99892385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(data_loader, model):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            true_labels.extend(target.cpu().numpy())\n",
    "            predictions.extend(torch.sigmoid(output).round().cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    return accuracy, f1, predictions, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a587cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "def prepare_dataset(X_train, Y_train, X_test, Y_test):\n",
    "\n",
    "\n",
    "    # Convert data to torch tensors\n",
    "    x_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    y_train = torch.tensor(Y_train.values, dtype=torch.long)\n",
    "    x_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "    y_test = torch.tensor(Y_test.values, dtype=torch.long)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "# print feature size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6111038",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = prepare_dataset(X_train, Y_train, X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471f05d4",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb708ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import torch.optim as optim\n",
    "\n",
    "# Hyperparameters\n",
    "LEARNING_RATE = 0.0023\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 25\n",
    "\n",
    "# # Calculate class weights\n",
    "class_weights = {0: 0.1, 1: 1.0} \n",
    "weights = torch.tensor([class_weights[1]], dtype=torch.float).to(device)\n",
    "\n",
    "\n",
    "model = Net(x_train.shape[1]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_data = TensorDataset(x_train.to(device), y_train.float().unsqueeze(1).to(device))  # Ensure y_train is float and of shape (batch_size, 1)\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_data = TensorDataset(x_test.to(device), y_test.float().unsqueeze(1).to(device))  # Ensure y_test is float and of shape (batch_size, 1)\n",
    "test_loader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "epoch_losses = []\n",
    "epoch_accuracies = []\n",
    "epoch_f1s = []\n",
    "\n",
    "\n",
    "try:\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)  # Move data to the device\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "\n",
    "            \n",
    "            # here update the output\n",
    "            \n",
    "            # negate the output to match the class weights\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Compute average loss\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        epoch_losses.append(avg_loss)\n",
    "\n",
    "        # Evaluate model and store metrics\n",
    "        train_accuracy, train_f1, _, _ = compute_metrics(train_loader, model)\n",
    "        epoch_accuracies.append(train_accuracy)\n",
    "        epoch_f1s.append(train_f1)\n",
    "\n",
    "        # Enhanced logging\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {avg_loss:.4f}, Accuracy: {train_accuracy:.4f}, F1 Score: {train_f1:.4f}\")\n",
    "except Exception as e:\n",
    "    # clean GPU memory\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "    # deallocate memory\n",
    "    del model\n",
    "    raise e\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a9dc28",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75acc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model \n",
    "torch.save(model.state_dict(), './models/malware_gru.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59898f79",
   "metadata": {},
   "source": [
    "# Testing trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a03016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# load model\n",
    "model = Net(173).to(device)\n",
    "model.load_state_dict(torch.load('./models/malware_gru.pth'))\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_accuracy, test_f1, predictions, true_labels = compute_metrics(test_loader, model)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix - Test Data')\n",
    "plt.show()\n",
    "\n",
    "# Plotting the training progress\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot for Loss\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(epoch_losses, linestyle='--', marker='o', color='#2ba7fc', label=f'Loss (Best: {min(epoch_losses):.4f})')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot for Accuracy\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(epoch_accuracies, linestyle='--', marker='o', color='#61d484', label=f'Accuracy (Best: {max(epoch_accuracies):.4f})')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot for F1 Score\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(epoch_f1s, linestyle='--', marker='o', color='#b85e4f', label=f'F1 Score (Best: {max(epoch_f1s):.4f})')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('Training F1 Score')\n",
    "plt.legend()\n",
    "\n",
    "plt.suptitle('Training Progress')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotting the testing results\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "metrics = ['Accuracy', 'F1 Score']\n",
    "values = [test_accuracy, test_f1]\n",
    "colors = ['#61d484', '#b85e4f']\n",
    "\n",
    "plt.bar(metrics, values, color=colors)\n",
    "plt.ylim(0, 1)\n",
    "for i, v in enumerate(values):\n",
    "    plt.text(i, v + 0.02, f\"{v:.4f}\", ha='center', va='bottom')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Test Metrics')\n",
    "plt.show()\n",
    "\n",
    "# bylo 2k na 2k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7516b2c0-3ce9-44fc-a8b6-e4c34c420283",
   "metadata": {},
   "source": [
    "# Validate the model on a separate Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c1ae5b-6cc1-4362-ba83-6f4c2491c82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "from pandas.core.dtypes import common as com\n",
    "import numpy as np\n",
    "\n",
    "def cast_timestamp(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Cast timestamp fields to seconds since epoch.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if com.is_timedelta64_dtype(df[col]):\n",
    "            df[col] = df[col].dt.total_seconds()  # This converts timedelta to float (seconds)\n",
    "        elif com.is_datetime64_any_dtype(df[col]):\n",
    "            df[col] = df[col].astype(np.int64) // 10**9  # Converts datetime64 to Unix timestamp (seconds)\n",
    "    return df\n",
    "\n",
    "# Load the validation dataset\n",
    "validation_dataset_filename = '../testdata/validation_malware.parquet'\n",
    "df_validation = pq.read_table(validation_dataset_filename).to_pandas()\n",
    "\n",
    "# Cast timestamps and handle NaNs\n",
    "df_validation = cast_timestamp(df_validation)\n",
    "df_validation.fillna(-1, inplace=True)\n",
    "\n",
    "# Remove disqualified columns\n",
    "for column in disqualified_columns:\n",
    "    if column in df_validation.columns:\n",
    "        df_validation.drop(column, axis=1, inplace=True)\n",
    "\n",
    "# Map the labels\n",
    "df_validation['label'] = df_validation['label'].map({'benign': 0, 'phishing': 1})\n",
    "\n",
    "# print number of columns\n",
    "\n",
    "\n",
    "# Extract features and labels\n",
    "X_val = df_validation.drop(['label', 'domain_name'], axis=1)\n",
    "y_val = df_validation['label']\n",
    "\n",
    "# Load the scaler\n",
    "scaler = joblib.load(\"boundaries/malware_gru_scaler.joblib\")\n",
    "\n",
    "# Scale the features\n",
    "y_val = y_val.tolist()\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "# convert to tensor\n",
    "X_val_scaled = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "# convert pandas series y_val to llist\n",
    "\n",
    "# print shape of X_val_scaled and y_val_tensor\n",
    "\n",
    "# print number of columns\n",
    "\n",
    "# print shape of X_val_scaled and y_val_tensor\n",
    "print(X_val_scaled.shape, y_val_tensor.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Load the trained model\n",
    "model = Net(feature_size=173)\n",
    "model.load_state_dict(torch.load('./models/malware_gru.pth'))\n",
    "model.eval()\n",
    "model.to('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "val_data = TensorDataset(X_val_scaled, y_val_tensor)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# Function to compute metrics and predictions\n",
    "def compute_metrics_and_predictions(data_loader, model):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            print(torch.sigmoid(output).round())\n",
    "            print(torch.sigmoid(output))\n",
    "            input()\n",
    "            true_labels.extend(target.cpu().numpy())\n",
    "            predictions.extend(torch.sigmoid(output).round().cpu().numpy())\n",
    "\n",
    "\n",
    "    return true_labels, predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get predictions and probabilities\n",
    "test_true_labels, test_predictions= compute_metrics_and_predictions(val_loader, model)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(test_true_labels, test_predictions)\n",
    "weighted_accuracy = (accuracy_score(np.array(test_true_labels) == 0, np.array(test_predictions) == 0) + accuracy_score(np.array(test_true_labels) == 1, np.array(test_predictions) == 1)) / 2\n",
    "precision = precision_score(test_true_labels, test_predictions)\n",
    "recall = recall_score(test_true_labels, test_predictions)\n",
    "f1 = f1_score(test_true_labels, test_predictions)\n",
    "tn, fp, fn, tp = confusion_matrix(test_true_labels, test_predictions).ravel()\n",
    "false_positive_rate = fp / (fp + tn)\n",
    "\n",
    "# Display metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Weighted Accuracy: {weighted_accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'False Positive Rate: {false_positive_rate}')\n",
    "\n",
    "# Display confusion matrix\n",
    "cm = confusion_matrix(test_true_labels, test_predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['benign', 'phishing'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix - Test Data')\n",
    "plt.show()\n",
    "\n",
    "# Identify misclassified domain names\n",
    "misclassified = df_validation.iloc[[i for i, (y_true, y_pred) in enumerate(zip(test_true_labels, test_predictions)) if y_true != y_pred]]\n",
    "misclassified_domains = misclassified['domain_name'].tolist()\n",
    "print(f'Misclassified domains: {misclassified_domains}')\n",
    "\n",
    "# bylo x 1000\n",
    "# 10 x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ca2912-6e1c-4ecf-a4eb-274882896e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "472a3593",
   "metadata": {},
   "source": [
    "# Make test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ec9657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "from pyarrow import Table\n",
    "\n",
    "# Load the model and scaler\n",
    "model = load_model('dga_binary_model.keras')\n",
    "scaler = joblib.load(\"dga_binary_scaler.joblib\")\n",
    "\n",
    "# #############################################################\n",
    "# EDIT this to specify benign / malicious datasets to use     #\n",
    "# #############################################################\n",
    "benign_dataset_filenames = [\n",
    "    '../feature-extraction/floor/benign_2312_anonymized.parquet',\n",
    "    '../feature-extraction/floor/umbrella_benign_FINISHED.parquet',\n",
    "]\n",
    "malicious_dataset_filenames = [\n",
    "    '../feature-extraction/floor/lex-dga-830k-pick.parquet'\n",
    "]\n",
    "# #############################################################\n",
    "# EDIT this for to set appropriate labels (malware, dga, ...) #\n",
    "# #############################################################\n",
    "benign_label = \"benign\"\n",
    "malicious_label = \"dga\"\n",
    "# #############################################################\n",
    "\n",
    "def union_tables(tables: [pa.Table]) -> pa.Table:\n",
    "    union_table = tables[0]\n",
    "    for table in tables[1:]:\n",
    "        right_not_in_union = union_table.join(right_table=table, keys='domain_name', join_type='right anti',\n",
    "                                              coalesce_keys=True, use_threads=True)\n",
    "        union_table = pa.concat_tables([union_table, right_not_in_union])\n",
    "    return union_table\n",
    "\n",
    "# Unify malicious datasets and benign datasets\n",
    "schema = (pq.read_table(malicious_dataset_filenames[0])).schema # Use the schema from the first malicious filename\n",
    "benign_tables = [pq.read_table(filename).cast(schema) for filename in benign_dataset_filenames]\n",
    "malicious_tables = [pq.read_table(filename).cast(schema) for filename in malicious_dataset_filenames]\n",
    "malicious = union_tables(malicious_tables)\n",
    "benign = union_tables(benign_tables)\n",
    "\n",
    "# Convert pyarrow tables to pandas dataframes\n",
    "df_benign = benign.to_pandas()\n",
    "df_malicious = malicious.to_pandas()\n",
    "\n",
    "# Set appropriate labels\n",
    "df_benign[\"label\"] = benign_label\n",
    "df_malicious[\"label\"] = malicious_label\n",
    "class_map = {benign_label: 0, malicious_label: 1}\n",
    "\n",
    "# Concatentate benign and malicious\n",
    "test_df = pd.concat([df_benign, df_malicious])\n",
    "\n",
    "# Handle NaNs\n",
    "test_df.fillna(-1, inplace=True)\n",
    "\n",
    "\n",
    "# Take only N random samples\n",
    "N = 500\n",
    "test_df = test_df.sample(n=N, random_state=42)\n",
    "\n",
    "total_predictions = 0\n",
    "correct_predictions = 0\n",
    "\n",
    "for index, row in test_df.iterrows():\n",
    "    domain_name = row['domain_name']\n",
    "    original_label = row['label']\n",
    "    \n",
    "    # Drop \"domain_name\" and \"label\" columns\n",
    "    feature_vector = pd.DataFrame([row])\n",
    "    feature_vector.drop(columns=['domain_name', 'label'], inplace=True)\n",
    "\n",
    "     # Scale the feature vector using the loaded scaler\n",
    "    scaled_feature_vector = scaler.transform(feature_vector)\n",
    "    \n",
    "    # Perform prediction\n",
    "    prediction = model.predict(scaled_feature_vector, verbose=0)\n",
    "    \n",
    "    # Extract the predicted class\n",
    "    predicted_label = \"benign\" if prediction < 0.5 else \"dga\"\n",
    "    \n",
    "    # Check if the prediction was correct\n",
    "    if original_label == predicted_label:\n",
    "        correct_predictions += 1\n",
    "    \n",
    "    total_predictions += 1\n",
    "    \n",
    "    # Print the result\n",
    "    result=\"WRONG\"\n",
    "    if predicted_label == original_label:\n",
    "        result=\"OK\"\n",
    "        \n",
    "    pred_disp = \"!!! DGA !!!\"\n",
    "    if predicted_label == \"benign\":\n",
    "        pred_disp = \"BENIGN\"\n",
    "        \n",
    "    \n",
    "    print(f\"{result} | {domain_name} ({original_label}), Predicted: {pred_disp}, Prob: {prediction}\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b3d6c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e63ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206433e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b47d300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
