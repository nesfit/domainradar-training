{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 12:05:53.100735: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-27 12:05:53.100765: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-27 12:05:53.101710: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-27 12:05:53.696623: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm \n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils.preprocess import NDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 12:05:56,186 - utils.preprocess - INFO - Benign dataset path: ../feature-extraction/floor/benign_combined.parquet\n",
      "2024-05-27 12:05:56,187 - utils.preprocess - INFO - Malign dataset path: ../feature-extraction/floor/malware_bp.parquet\n",
      "2024-05-27 12:05:56,735 - utils.preprocess - INFO - Number of records in combined dataset: 962074\n",
      "2024-05-27 12:06:53,606 - utils.preprocess - INFO - Decision tree model saved to models/decision_tree_model.joblib\n",
      "2024-05-27 12:06:54,720 - utils.preprocess - INFO - New feature 'dtree_prob' created from decision tree predictions.\n",
      "2024-05-27 12:06:56,350 - utils.preprocess - INFO - Decision Tree Train Accuracy: 0.94\n",
      "2024-05-27 12:06:56,351 - utils.preprocess - INFO - Decision Tree Test Accuracy: 0.92\n",
      "2024-05-27 12:09:01,911 - utils.preprocess - INFO - Decision Tree Cross-Validation Scores: [0.91812705 0.91794594 0.91831389]\n",
      "2024-05-27 12:09:02,150 - utils.preprocess - INFO - Generated class map: {'benign_2312:unknown': 0, 'benign_2310:unknown': 0, 'malware:unknown': 1}\n",
      "2024-05-27 12:09:05,043 - utils.preprocess - INFO - Outliers thresholds saved to models/outliers.joblib\n",
      "2024-05-27 12:09:05,539 - utils.preprocess - INFO - Outliers removed from dns_A_count: 528 rows\n",
      "2024-05-27 12:09:05,817 - utils.preprocess - INFO - Outliers removed from dns_AAAA_count: 60 rows\n",
      "2024-05-27 12:09:06,094 - utils.preprocess - INFO - Outliers removed from dns_MX_count: 56 rows\n",
      "2024-05-27 12:09:06,369 - utils.preprocess - INFO - Outliers removed from dns_NS_count: 17 rows\n",
      "2024-05-27 12:09:06,648 - utils.preprocess - INFO - Outliers removed from dns_TXT_count: 1868 rows\n",
      "2024-05-27 12:09:07,429 - utils.preprocess - INFO - Outliers removed from dns_zone_level: 541 rows\n",
      "2024-05-27 12:09:07,708 - utils.preprocess - INFO - Outliers removed from dns_zone_digit_count: 918 rows\n",
      "2024-05-27 12:09:07,977 - utils.preprocess - INFO - Outliers removed from dns_zone_len: 7 rows\n",
      "2024-05-27 12:09:09,014 - utils.preprocess - INFO - Outliers removed from dns_ttl_avg: 16 rows\n",
      "2024-05-27 12:09:10,574 - utils.preprocess - INFO - Outliers removed from dns_soa_primary_ns_digit_count: 10 rows\n",
      "2024-05-27 12:09:11,624 - utils.preprocess - INFO - Outliers removed from dns_soa_email_digit_count: 1197 rows\n",
      "2024-05-27 12:09:12,409 - utils.preprocess - INFO - Outliers removed from dns_soa_refresh: 37 rows\n",
      "2024-05-27 12:09:12,679 - utils.preprocess - INFO - Outliers removed from dns_soa_retry: 9 rows\n",
      "2024-05-27 12:09:12,952 - utils.preprocess - INFO - Outliers removed from dns_soa_expire: 74 rows\n",
      "2024-05-27 12:09:13,228 - utils.preprocess - INFO - Outliers removed from dns_soa_min_ttl: 7 rows\n",
      "2024-05-27 12:09:14,792 - utils.preprocess - INFO - Outliers removed from dns_txt_external_verification_score: 671 rows\n",
      "2024-05-27 12:09:15,357 - utils.preprocess - INFO - Outliers removed from dns_txt_dkim_exists: 1823 rows\n",
      "2024-05-27 12:09:15,639 - utils.preprocess - INFO - Outliers removed from dns_txt_dmarc_exists: 2159 rows\n",
      "2024-05-27 12:09:15,927 - utils.preprocess - INFO - Outliers removed from ip_count: 110 rows\n",
      "2024-05-27 12:09:16,204 - utils.preprocess - INFO - Outliers removed from ip_mean_average_rtt: 92 rows\n",
      "2024-05-27 12:09:17,789 - utils.preprocess - INFO - Outliers removed from ip_distinct_as_count: 90 rows\n",
      "2024-05-27 12:09:18,326 - utils.preprocess - INFO - Outliers removed from tls_chain_len: 1 rows\n",
      "2024-05-27 12:09:19,378 - utils.preprocess - INFO - Outliers removed from tls_root_cert_validity_len: 24 rows\n",
      "2024-05-27 12:09:22,224 - utils.preprocess - INFO - Outliers removed from tls_subject_count: 2875 rows\n",
      "2024-05-27 12:09:23,262 - utils.preprocess - INFO - Outliers removed from tls_unique_SLD_count: 451 rows\n",
      "2024-05-27 12:09:23,794 - utils.preprocess - INFO - Outliers removed from lex_name_len: 11 rows\n",
      "2024-05-27 12:09:24,322 - utils.preprocess - INFO - Outliers removed from lex_phishing_keyword_count: 53 rows\n",
      "2024-05-27 12:09:24,607 - utils.preprocess - INFO - Outliers removed from lex_benign_keyword_count: 7 rows\n",
      "2024-05-27 12:09:24,893 - utils.preprocess - INFO - Outliers removed from lex_consecutive_chars: 147 rows\n",
      "2024-05-27 12:09:25,170 - utils.preprocess - INFO - Outliers removed from lex_tld_len: 169 rows\n",
      "2024-05-27 12:09:25,696 - utils.preprocess - INFO - Outliers removed from lex_sld_len: 58 rows\n",
      "2024-05-27 12:09:26,220 - utils.preprocess - INFO - Outliers removed from lex_sld_digit_count: 802 rows\n",
      "2024-05-27 12:09:26,496 - utils.preprocess - INFO - Outliers removed from lex_sld_digit_ratio: 2736 rows\n",
      "2024-05-27 12:09:26,764 - utils.preprocess - INFO - Outliers removed from lex_sld_phishing_keyword_count: 110 rows\n",
      "2024-05-27 12:09:27,030 - utils.preprocess - INFO - Outliers removed from lex_sld_vowel_count: 1 rows\n",
      "2024-05-27 12:09:27,551 - utils.preprocess - INFO - Outliers removed from lex_sld_consonant_count: 16 rows\n",
      "2024-05-27 12:09:28,085 - utils.preprocess - INFO - Outliers removed from lex_sld_non_alphanum_count: 1325 rows\n",
      "2024-05-27 12:09:28,355 - utils.preprocess - INFO - Outliers removed from lex_sld_non_alphanum_ratio: 827 rows\n",
      "2024-05-27 12:09:28,623 - utils.preprocess - INFO - Outliers removed from lex_sld_hex_count: 1 rows\n",
      "2024-05-27 12:09:29,145 - utils.preprocess - INFO - Outliers removed from lex_sub_count: 70 rows\n",
      "2024-05-27 12:09:30,193 - utils.preprocess - INFO - Outliers removed from lex_sub_max_consonant_len: 224 rows\n",
      "2024-05-27 12:09:30,719 - utils.preprocess - INFO - Outliers removed from lex_sub_digit_count: 2734 rows\n",
      "2024-05-27 12:09:30,983 - utils.preprocess - INFO - Outliers removed from lex_sub_digit_ratio: 3 rows\n",
      "2024-05-27 12:09:31,246 - utils.preprocess - INFO - Outliers removed from lex_sub_vowel_count: 18 rows\n",
      "2024-05-27 12:09:31,779 - utils.preprocess - INFO - Outliers removed from lex_sub_consonant_count: 202 rows\n",
      "2024-05-27 12:09:32,300 - utils.preprocess - INFO - Outliers removed from lex_sub_non_alphanum_count: 242 rows\n",
      "2024-05-27 12:09:32,820 - utils.preprocess - INFO - Outliers removed from lex_sub_hex_count: 382 rows\n",
      "2024-05-27 12:09:33,594 - utils.preprocess - INFO - Outliers removed from lex_phishing_trigram_matches: 11 rows\n",
      "2024-05-27 12:09:33,857 - utils.preprocess - INFO - Outliers removed from lex_phishing_tetragram_matches: 455 rows\n",
      "2024-05-27 12:09:34,131 - utils.preprocess - INFO - Outliers removed from lex_phishing_pentagram_matches: 25 rows\n",
      "2024-05-27 12:09:34,653 - utils.preprocess - INFO - Outliers removed from lex_malware_trigram_matches: 1 rows\n",
      "2024-05-27 12:09:34,918 - utils.preprocess - INFO - Outliers removed from lex_malware_tetragram_matches: 44 rows\n",
      "2024-05-27 12:09:35,419 - utils.preprocess - INFO - Outliers removed from lex_dga_trigram_matches: 1 rows\n",
      "2024-05-27 12:09:35,682 - utils.preprocess - INFO - Outliers removed from lex_dga_tetragram_matches: 128 rows\n",
      "2024-05-27 12:09:35,945 - utils.preprocess - INFO - Outliers removed from lex_avg_part_len: 2 rows\n",
      "2024-05-27 12:09:36,203 - utils.preprocess - INFO - Outliers removed from lex_stdev_part_lens: 124 rows\n",
      "2024-05-27 12:09:36,471 - utils.preprocess - INFO - Outliers removed from lex_longest_part_len: 7 rows\n",
      "2024-05-27 12:09:36,733 - utils.preprocess - INFO - Outliers removed from lex_short_part_count: 2 rows\n",
      "2024-05-27 12:09:37,493 - utils.preprocess - INFO - Outliers removed from lex_superlong_part_count: 4934 rows\n",
      "2024-05-27 12:09:38,005 - utils.preprocess - INFO - Outliers removed from lex_ipv4_in_domain: 450 rows\n",
      "2024-05-27 12:09:38,269 - utils.preprocess - INFO - Outliers removed from lex_has_trusted_suffix: 7636 rows\n",
      "2024-05-27 12:09:38,534 - utils.preprocess - INFO - Outliers removed from lex_has_wellknown_suffix: 7050 rows\n",
      "2024-05-27 12:09:38,795 - utils.preprocess - INFO - Outliers removed from lex_has_cdn_suffix: 6517 rows\n",
      "2024-05-27 12:09:39,047 - utils.preprocess - INFO - Outliers removed from lex_has_vps_suffix: 1957 rows\n",
      "2024-05-27 12:09:39,298 - utils.preprocess - INFO - Outliers removed from lex_has_img_suffix: 544 rows\n",
      "2024-05-27 12:09:40,513 - utils.preprocess - INFO - Outliers removed from geo_lat_stdev: 118 rows\n",
      "2024-05-27 12:09:43,425 - utils.preprocess - INFO - Outliers removed from geo_estimated_area: 24 rows\n",
      "2024-05-27 12:09:43,677 - utils.preprocess - INFO - Outliers removed from rdap_registration_period: 14 rows\n",
      "2024-05-27 12:09:44,184 - utils.preprocess - INFO - Outliers removed from rdap_time_from_last_change: 1536 rows\n",
      "2024-05-27 12:09:44,683 - utils.preprocess - INFO - Outliers removed from rdap_has_dnssec: 13319 rows\n",
      "2024-05-27 12:09:45,412 - utils.preprocess - INFO - Outliers removed from rdap_registrant_name_len: 100 rows\n",
      "2024-05-27 12:09:45,897 - utils.preprocess - INFO - Outliers removed from rdap_admin_name_len: 4039 rows\n",
      "2024-05-27 12:09:46,150 - utils.preprocess - INFO - Outliers removed from rdap_admin_name_entropy: 3885 rows\n",
      "2024-05-27 12:09:46,402 - utils.preprocess - INFO - Outliers removed from rdap_admin_email_len: 3090 rows\n",
      "2024-05-27 12:09:46,889 - utils.preprocess - INFO - Outliers removed from rdap_ip_v4_count: 14 rows\n",
      "2024-05-27 12:09:47,135 - utils.preprocess - INFO - Outliers removed from rdap_ip_v6_count: 7 rows\n",
      "2024-05-27 12:09:49,239 - utils.preprocess - INFO - Completed outlier removal.\n",
      "2024-05-27 12:09:51,133 - utils.preprocess - INFO - Applying StandardScaler scaling to the features.\n",
      "2024-05-27 12:09:52,730 - utils.preprocess - INFO - Scaler saved to models/scaler.joblib\n",
      "2024-05-27 12:09:52,737 - utils.preprocess - INFO - Scaling applied to the features\n",
      "\n",
      "2024-05-27 12:09:52,804 - utils.preprocess - INFO - Head of modified combined dataset:\n",
      "2024-05-27 12:09:52,805 - utils.preprocess - INFO -         dns_has_dnskey  dns_A_count  dns_AAAA_count  dns_MX_count  \\\n",
      "1            -0.331403    -0.089957       -0.390788     -0.555299   \n",
      "2            -0.331403    -0.819933       -0.390788     -0.555299   \n",
      "3            -0.331403    -0.819933       -0.390788     -0.555299   \n",
      "4            -0.331403    -0.089957       -0.390788      0.136439   \n",
      "5            -0.331403    -0.089957       -0.390788     -0.555299   \n",
      "...                ...          ...             ...           ...   \n",
      "962069       -0.331403    -0.819933       -0.390788     -0.555299   \n",
      "962070       -0.331403    -0.089957       -0.390788     -0.555299   \n",
      "962071       -0.331403     0.640019        1.900324     -0.555299   \n",
      "962072       -0.331403    -0.089957       -0.390788      0.136439   \n",
      "962073       -0.331403    -0.819933       -0.390788     -0.555299   \n",
      "\n",
      "        dns_NS_count  dns_TXT_count  dns_SOA_count  dns_CNAME_count  \\\n",
      "1          -0.811427      -0.460858      -0.954227        -0.486081   \n",
      "2          -0.811427      -0.460858      -0.954227         2.057272   \n",
      "3          -0.811427      -0.460858      -0.954227         2.057272   \n",
      "4           1.653451       0.037641       1.047969        -0.486081   \n",
      "5          -0.811427      -0.460858      -0.954227        -0.486081   \n",
      "...              ...            ...            ...              ...   \n",
      "962069     -0.811427      -0.460858      -0.954227         2.057272   \n",
      "962070      0.421012       0.536140       1.047969        -0.486081   \n",
      "962071      0.421012       0.037641       1.047969        -0.486081   \n",
      "962072      0.421012      -0.460858       1.047969        -0.486081   \n",
      "962073     -0.811427      -0.460858      -0.954227         2.057272   \n",
      "\n",
      "        dns_zone_level  dns_zone_digit_count  ...  rdap_ip_v6_count  \\\n",
      "1             4.650603             -0.239272  ...         -0.622000   \n",
      "2            -0.274298             -0.239272  ...         -0.622000   \n",
      "3            -0.274298             -0.239272  ...         -0.622000   \n",
      "4            -0.274298             -0.239272  ...         -0.622000   \n",
      "5             7.113053              2.339070  ...         -0.622000   \n",
      "...                ...                   ...  ...               ...   \n",
      "962069       -0.274298             -0.239272  ...         -0.622000   \n",
      "962070       -0.274298             -0.239272  ...          1.308915   \n",
      "962071       -0.274298             -0.239272  ...          0.021638   \n",
      "962072       -0.274298             -0.239272  ...         -0.622000   \n",
      "962073       -0.274298             -0.239272  ...         -0.300181   \n",
      "\n",
      "        rdap_ip_shortest_v4_prefix_len  rdap_ip_longest_v4_prefix_len  \\\n",
      "1                             0.047967                      -0.329203   \n",
      "2                             1.341158                       0.820554   \n",
      "3                            -0.670473                      -0.712455   \n",
      "4                             1.053782                       0.820554   \n",
      "5                             0.335342                      -0.073701   \n",
      "...                                ...                            ...   \n",
      "962069                       -0.383097                      -0.329203   \n",
      "962070                       -0.239409                       0.309551   \n",
      "962071                        1.053782                       0.565052   \n",
      "962072                        0.191654                      -0.201452   \n",
      "962073                        0.191654                      -0.201452   \n",
      "\n",
      "        rdap_ip_shortest_v6_prefix_len  rdap_ip_longest_v6_prefix_len  \\\n",
      "1                            -0.824673                      -0.816303   \n",
      "2                            -0.824673                      -0.816303   \n",
      "3                            -0.824673                      -0.816303   \n",
      "4                            -0.824673                      -0.816303   \n",
      "5                            -0.824673                      -0.816303   \n",
      "...                                ...                            ...   \n",
      "962069                       -0.824673                      -0.816303   \n",
      "962070                        1.098572                       0.845555   \n",
      "962071                        1.098572                       0.845555   \n",
      "962072                       -0.824673                      -0.816303   \n",
      "962073                        1.098572                       0.845555   \n",
      "\n",
      "        rdap_ip_avg_admin_name_len  rdap_ip_avg_admin_name_entropy  \\\n",
      "1                        -1.421485                       -1.627849   \n",
      "2                         0.068270                        0.226220   \n",
      "3                         0.068270                        0.356021   \n",
      "4                        -1.421485                       -1.627849   \n",
      "5                         0.068270                        0.356021   \n",
      "...                            ...                             ...   \n",
      "962069                    0.068270                        0.356021   \n",
      "962070                   -0.557603                        0.820471   \n",
      "962071                    1.328832                       -0.327845   \n",
      "962072                   -1.077695                        2.578997   \n",
      "962073                   -0.103625                        0.574520   \n",
      "\n",
      "        rdap_ip_avg_admin_email_len  rdap_ip_avg_admin_email_entropy  \\\n",
      "1                         -1.483622                        -1.524414   \n",
      "2                          1.587737                         0.195967   \n",
      "3                          0.952284                         0.401177   \n",
      "4                         -1.483622                        -1.524414   \n",
      "5                          0.952284                         0.401177   \n",
      "...                             ...                              ...   \n",
      "962069                     0.952284                         0.401177   \n",
      "962070                    -0.017190                         0.432378   \n",
      "962071                    -1.483622                        -1.524414   \n",
      "962072                    -0.318624                         2.091325   \n",
      "962073                     1.005238                         0.446489   \n",
      "\n",
      "        dtree_prob  \n",
      "1        -1.017337  \n",
      "2         0.497017  \n",
      "3        -1.017337  \n",
      "4        -1.017337  \n",
      "5         1.064900  \n",
      "...            ...  \n",
      "962069   -1.017337  \n",
      "962070   -1.017337  \n",
      "962071   -1.017337  \n",
      "962072    1.064900  \n",
      "962073   -1.017337  \n",
      "\n",
      "[882261 rows x 171 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Subset:\n",
      "Name: dataset_../feature-extraction/floor/malwarebp_2024-05-27.parquet\n",
      "Features:\n",
      "   Feature_0  Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  \\\n",
      "0   3.017475  -0.819933  -0.390788  -0.555299  -0.811427  -0.460858   \n",
      "1  -0.331403  -0.089957  -0.390788   2.903392   1.653451   1.034639   \n",
      "2  -0.331403  -0.819933  -0.390788  -0.555299  -0.811427  -0.460858   \n",
      "3  -0.331403  -0.089957  -0.390788   0.136439  -0.811427   0.037641   \n",
      "4   3.017475   0.640019   1.900324   0.828177   0.421012   0.037641   \n",
      "5  -0.331403  -0.089957  -0.390788   0.828177   0.421012   0.037641   \n",
      "6  -0.331403  -0.089957   1.900324  -0.555299  -0.811427   0.037641   \n",
      "7  -0.331403  -0.819933  -0.390788  -0.555299  -0.811427  -0.460858   \n",
      "8  -0.331403  -0.089957  -0.390788   0.136439   0.421012   0.037641   \n",
      "9  -0.331403   2.099971  -0.390788   0.136439   1.653451   0.536140   \n",
      "\n",
      "   Feature_6  Feature_7  Feature_8  Feature_9  ...  Feature_161  Feature_162  \\\n",
      "0  -0.954227  -0.486081  -0.274298  -0.239272  ...    -0.622000    -2.107353   \n",
      "1   1.047969  -0.486081  -0.274298  -0.239272  ...     2.274373     0.047967   \n",
      "2  -0.954227   2.057272   2.188153   4.917413  ...     1.952554    -0.095721   \n",
      "3  -0.954227  -0.486081  -0.274298  -0.239272  ...    -0.622000     0.191654   \n",
      "4   1.047969  -0.486081  -0.274298  -0.239272  ...     1.952554    -0.383097   \n",
      "5   1.047969  -0.486081  -0.274298  -0.239272  ...    -0.622000     0.622718   \n",
      "6  -0.954227  -0.486081  -0.274298  -0.239272  ...     0.021638    -2.107353   \n",
      "7  -0.954227   2.057272  -0.274298  -0.239272  ...    -0.300181    -0.383097   \n",
      "8   1.047969  -0.486081  -0.274298  -0.239272  ...    -0.622000     1.341158   \n",
      "9   1.047969  -0.486081  -0.274298  -0.239272  ...     0.665277    -0.383097   \n",
      "\n",
      "   Feature_163  Feature_164  Feature_165  Feature_166  Feature_167  \\\n",
      "0    -2.245464    -0.824673    -0.816303    -1.421485    -1.627849   \n",
      "1     0.692803     0.858166     1.624552    -0.227268     0.127811   \n",
      "2    -0.456954     0.858166     0.637823     0.068270     0.356021   \n",
      "3    -0.201452    -0.824673    -0.816303     0.068270     0.356021   \n",
      "4     0.309551     1.098572     0.845555    -0.470334     0.833109   \n",
      "5     0.820554    -0.824673    -0.816303    -0.069246     0.556828   \n",
      "6    -2.245464     2.060195     1.676485     1.099639    -1.022421   \n",
      "7    -0.712455     0.617761     0.430091     1.443429    -0.556438   \n",
      "8     0.820554    -0.824673    -0.816303     0.182867     0.375127   \n",
      "9     0.820554     0.617761     1.053288     0.936791    -0.135054   \n",
      "\n",
      "   Feature_168  Feature_169  Feature_170  \n",
      "0    -1.483622    -1.524414    -1.017337  \n",
      "1     0.562093     0.148607    -1.017337  \n",
      "2     0.952284     0.401177    -1.017337  \n",
      "3     0.210921     1.147714     1.064900  \n",
      "4    -0.149169     0.257464     1.064900  \n",
      "5    -0.212715     2.135289     1.046634  \n",
      "6    -0.353927     0.282261     1.064900  \n",
      "7     1.270011     0.261056    -1.017337  \n",
      "8     0.105012     1.365030    -1.017337  \n",
      "9     1.147379     0.165080     1.064900  \n",
      "\n",
      "[10 rows x 171 columns]\n",
      "Labels:\n",
      "   Label\n",
      "0    1.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.0\n",
      "6    0.0\n",
      "7    0.0\n",
      "8    1.0\n",
      "9    0.0\n",
      "Dimension: 171\n",
      "dns_has_dnskey\n",
      "dns_A_count\n",
      "dns_AAAA_count\n",
      "dns_MX_count\n",
      "dns_NS_count\n",
      "dns_TXT_count\n",
      "dns_SOA_count\n",
      "dns_CNAME_count\n",
      "dns_zone_level\n",
      "dns_zone_digit_count\n",
      "dns_zone_len\n",
      "dns_zone_entropy\n",
      "dns_resolved_record_types\n",
      "dns_dnssec_score\n",
      "dns_ttl_avg\n",
      "dns_ttl_stdev\n",
      "dns_ttl_low\n",
      "dns_ttl_mid\n",
      "dns_ttl_distinct_count\n",
      "dns_soa_primary_ns_level\n",
      "dns_soa_primary_ns_digit_count\n",
      "dns_soa_primary_ns_len\n",
      "dns_soa_primary_ns_entropy\n",
      "dns_soa_email_level\n",
      "dns_soa_email_digit_count\n",
      "dns_soa_email_len\n",
      "dns_soa_email_entropy\n",
      "dns_soa_refresh\n",
      "dns_soa_retry\n",
      "dns_soa_expire\n",
      "dns_soa_min_ttl\n",
      "dns_domain_name_in_mx\n",
      "dns_mx_avg_len\n",
      "dns_mx_avg_entropy\n",
      "dns_txt_avg_len\n",
      "dns_txt_avg_entropy\n",
      "dns_txt_external_verification_score\n",
      "dns_txt_spf_exists\n",
      "dns_txt_dkim_exists\n",
      "dns_txt_dmarc_exists\n",
      "ip_count\n",
      "ip_mean_average_rtt\n",
      "ip_v4_ratio\n",
      "ip_a_aaaa_to_all_ratio\n",
      "ip_entropy\n",
      "ip_as_address_entropy\n",
      "ip_asn_entropy\n",
      "ip_distinct_as_count\n",
      "tls_has_tls\n",
      "tls_chain_len\n",
      "tls_is_self_signed\n",
      "tls_negotiated_version_id\n",
      "tls_negotiated_cipher_id\n",
      "tls_root_cert_validity_len\n",
      "tls_leaf_cert_validity_len\n",
      "tls_broken_chain\n",
      "tls_expired_chain\n",
      "tls_total_extension_count\n",
      "tls_critical_extensions\n",
      "tls_with_policies_crt_count\n",
      "tls_percentage_crt_with_policies\n",
      "tls_x509_anypolicy_crt_count\n",
      "tls_iso_policy_crt_count\n",
      "tls_joint_isoitu_policy_crt_count\n",
      "tls_subject_count\n",
      "tls_server_auth_crt_count\n",
      "tls_client_auth_crt_count\n",
      "tls_CA_certs_in_chain_ratio\n",
      "tls_unique_SLD_count\n",
      "tls_common_name_count\n",
      "lex_name_len\n",
      "lex_has_digit\n",
      "lex_phishing_keyword_count\n",
      "lex_benign_keyword_count\n",
      "lex_consecutive_chars\n",
      "lex_tld_len\n",
      "lex_tld_abuse_score\n",
      "lex_sld_len\n",
      "lex_sld_norm_entropy\n",
      "lex_sld_digit_count\n",
      "lex_sld_digit_ratio\n",
      "lex_sld_phishing_keyword_count\n",
      "lex_sld_vowel_count\n",
      "lex_sld_vowel_ratio\n",
      "lex_sld_consonant_count\n",
      "lex_sld_consonant_ratio\n",
      "lex_sld_non_alphanum_count\n",
      "lex_sld_non_alphanum_ratio\n",
      "lex_sld_hex_count\n",
      "lex_sld_hex_ratio\n",
      "lex_sub_count\n",
      "lex_stld_unique_char_count\n",
      "lex_begins_with_digit\n",
      "lex_www_flag\n",
      "lex_sub_max_consonant_len\n",
      "lex_sub_norm_entropy\n",
      "lex_sub_digit_count\n",
      "lex_sub_digit_ratio\n",
      "lex_sub_vowel_count\n",
      "lex_sub_vowel_ratio\n",
      "lex_sub_consonant_count\n",
      "lex_sub_consonant_ratio\n",
      "lex_sub_non_alphanum_count\n",
      "lex_sub_non_alphanum_ratio\n",
      "lex_sub_hex_count\n",
      "lex_sub_hex_ratio\n",
      "lex_phishing_bigram_matches\n",
      "lex_phishing_trigram_matches\n",
      "lex_phishing_tetragram_matches\n",
      "lex_phishing_pentagram_matches\n",
      "lex_malware_bigram_matches\n",
      "lex_malware_trigram_matches\n",
      "lex_malware_tetragram_matches\n",
      "lex_dga_bigram_matches\n",
      "lex_dga_trigram_matches\n",
      "lex_dga_tetragram_matches\n",
      "lex_avg_part_len\n",
      "lex_stdev_part_lens\n",
      "lex_longest_part_len\n",
      "lex_short_part_count\n",
      "lex_medium_part_count\n",
      "lex_long_part_count\n",
      "lex_superlong_part_count\n",
      "lex_shortest_sub_len\n",
      "lex_ipv4_in_domain\n",
      "lex_has_trusted_suffix\n",
      "lex_has_wellknown_suffix\n",
      "lex_has_cdn_suffix\n",
      "lex_has_vps_suffix\n",
      "lex_has_img_suffix\n",
      "lex_suffix_score\n",
      "geo_countries_count\n",
      "geo_continents_count\n",
      "geo_malic_host_country\n",
      "geo_lat_stdev\n",
      "geo_lon_stdev\n",
      "geo_mean_lat\n",
      "geo_mean_lon\n",
      "geo_min_lat\n",
      "geo_max_lat\n",
      "geo_min_lon\n",
      "geo_max_lon\n",
      "geo_lat_range\n",
      "geo_lon_range\n",
      "geo_centroid_lat\n",
      "geo_centroid_lon\n",
      "geo_estimated_area\n",
      "rdap_registration_period\n",
      "rdap_domain_age\n",
      "rdap_time_from_last_change\n",
      "rdap_domain_active_time\n",
      "rdap_has_dnssec\n",
      "rdap_registrar_name_len\n",
      "rdap_registrar_name_entropy\n",
      "rdap_registrant_name_len\n",
      "rdap_registrant_name_entropy\n",
      "rdap_admin_name_len\n",
      "rdap_admin_name_entropy\n",
      "rdap_admin_email_len\n",
      "rdap_admin_email_entropy\n",
      "rdap_ip_v4_count\n",
      "rdap_ip_v6_count\n",
      "rdap_ip_shortest_v4_prefix_len\n",
      "rdap_ip_longest_v4_prefix_len\n",
      "rdap_ip_shortest_v6_prefix_len\n",
      "rdap_ip_longest_v6_prefix_len\n",
      "rdap_ip_avg_admin_name_len\n",
      "rdap_ip_avg_admin_name_entropy\n",
      "rdap_ip_avg_admin_email_len\n",
      "rdap_ip_avg_admin_email_entropy\n",
      "dtree_prob\n",
      "Index(['dns_has_dnskey', 'dns_A_count', 'dns_AAAA_count', 'dns_MX_count',\n",
      "       'dns_NS_count', 'dns_TXT_count', 'dns_SOA_count', 'dns_CNAME_count',\n",
      "       'dns_zone_level', 'dns_zone_digit_count',\n",
      "       ...\n",
      "       'rdap_ip_v6_count', 'rdap_ip_shortest_v4_prefix_len',\n",
      "       'rdap_ip_longest_v4_prefix_len', 'rdap_ip_shortest_v6_prefix_len',\n",
      "       'rdap_ip_longest_v6_prefix_len', 'rdap_ip_avg_admin_name_len',\n",
      "       'rdap_ip_avg_admin_name_entropy', 'rdap_ip_avg_admin_email_len',\n",
      "       'rdap_ip_avg_admin_email_entropy', 'dtree_prob'],\n",
      "      dtype='object', length=171)\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 15\n",
    "\n",
    "\n",
    "#The whole preprocessing step happens here\n",
    "#Missing values set to -1\n",
    "#Outliers are removed\n",
    "#Encoding of categorical variables\n",
    "#Min-Max scaling, sigmoid transformation (only if cnn is used)\n",
    "input_data = {\n",
    "    'benign': '../feature-extraction/floor/benign_combined.parquet', # benign_2312 + umbrella_benign_FINISHED\n",
    "    #'malign': '../feature-extraction/floor/phishing_final_2024.parquet'\n",
    "    'malign': '../feature-extraction/floor/malware_bp.parquet'\n",
    "}\n",
    "\n",
    "dataset = NDF(\"malware\", True, input_data=input_data, one_line_processing=False)\n",
    "\n",
    "# Convert the unique feature names to a list\n",
    "feature_names_list = dataset['feature_names'].unique().tolist()\n",
    "\n",
    "# Print each feature name individually\n",
    "for feature in feature_names_list:\n",
    "    print(feature)\n",
    "\n",
    "print(dataset['feature_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smote Class Imbalance Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New class distribution after SMOTE:\n",
      "Class 0.0: 17427\n",
      "Class 1.0: 17427\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#imprt SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.array(dataset['features']), np.array(dataset['labels']), test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train_smote, y_train_smote = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "# Check the new class distribution\n",
    "new_label_counts = Counter(y_train_smote)\n",
    "print(\"New class distribution after SMOTE:\")\n",
    "for label, count in new_label_counts.items():\n",
    "    print(f\"Class {label}: {count}\")\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "x_train = torch.tensor(x_train_smote, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)  # Convert x_test to tensor\n",
    "y_train = torch.tensor(y_train_smote, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long) \n",
    "feature_size = x_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# Function to calculate the next perfect square greater than a given number\n",
    "def next_perfect_square(n):\n",
    "    next_square = math.ceil(n**0.5)**2\n",
    "    return next_square\n",
    "\n",
    "feature_size = x_train.shape[1]\n",
    "desired_size = next_perfect_square(feature_size)\n",
    "side_size = int(desired_size ** 0.5)\n",
    "\n",
    "# Calculate padding required to achieve the desired size\n",
    "padding = desired_size - feature_size\n",
    "\n",
    "# Applying dynamic padding\n",
    "if padding > 0:\n",
    "    x_train_padded = F.pad(x_train, (0, padding), 'constant', 0)\n",
    "    x_test_padded = F.pad(x_test, (0, padding), 'constant', 0)\n",
    "else:\n",
    "    x_train_padded = x_train\n",
    "    x_test_padded = x_test\n",
    "\n",
    "# Reshape the data to the new dynamically calculated square shape\n",
    "x_train = x_train_padded.view(-1, 1, side_size, side_size)\n",
    "x_test = x_test_padded.view(-1, 1, side_size, side_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, side_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Adjust the size calculation based on the number of convolutional layers\n",
    "        self.fc1 = nn.Linear(128 * (side_size-6)**2, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 128)\n",
    "        self.fc4 = nn.Linear(128, 2)\n",
    "        \n",
    "        # Optionally use dropout\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        \n",
    "        print(\"CNN model created\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout1(x)  # Dropout applied after flattening\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)  # Dropout applied after first fully connected layer\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x) # No softmax here, as CrossEntropyLoss applies LogSoftmax internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model's training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model created\n",
      "Epoch 1/3 - Loss: 0.1125, Accuracy: 0.9731, F1 Score: 0.9725\n",
      "Epoch 2/3 - Loss: 0.0750, Accuracy: 0.9798, F1 Score: 0.9796\n",
      "Epoch 3/3 - Loss: 0.0666, Accuracy: 0.9838, F1 Score: 0.9838\n",
      "Model training complete and saved.\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.000238\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 15\n",
    "\n",
    "model = Net(side_size).to(device)  # Classic fully connected model\n",
    "\n",
    "\n",
    "#CANNOT RETURN SOFT MAX AS THE LOSS FUNCTION IS CROSS ENTROPY\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_data = TensorDataset(x_train, y_train.long())\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Function to compute accuracy and F1 score\n",
    "def compute_metrics(data_loader, model):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)  # Move data to the device\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            true_labels.extend(target.cpu().tolist())  # Move data back to CPU for scoring\n",
    "            predictions.extend(pred.view_as(target).cpu().tolist())  # Move data back to CPU\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    return accuracy, f1\n",
    "\n",
    "epoch_losses = []\n",
    "epoch_accuracies = []\n",
    "epoch_f1s = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)  # Move data to the device\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Compute average loss\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    epoch_losses.append(avg_loss)\n",
    "\n",
    "    # Evaluate model and store metrics\n",
    "    train_accuracy, train_f1 = compute_metrics(train_loader, model)\n",
    "    epoch_accuracies.append(train_accuracy)\n",
    "    epoch_f1s.append(train_f1)\n",
    "\n",
    "    # Enhanced logging\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {avg_loss:.4f}, Accuracy: {train_accuracy:.4f}, F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'models/phishing_cnn_model_state_dict.pth')\n",
    "print(\"Model training complete and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics:\n",
      "accuracy: 0.9793\n",
      "f1: 0.9794\n",
      "precision: 0.9795\n",
      "recall: 0.9793\n",
      "roc_auc_score: 0.9903\n",
      "cross_entropy_loss: 0.0765\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def compute_metrics(data_loader, model, criterion):\n",
    "    \"\"\"\n",
    "    Computes a wide range of performance metrics for the given model evaluated on the provided DataLoader.\n",
    "    \n",
    "    Parameters:\n",
    "        data_loader (DataLoader): DataLoader for evaluation data.\n",
    "        model (torch.nn.Module): The neural network model to evaluate.\n",
    "        criterion (torch.nn.Module): Loss function used for the model.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing various performance metrics.\n",
    "    \"\"\"\n",
    "    model.eval()  # Switch model to evaluation mode\n",
    "    true_labels, predictions, probs, losses = [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            prob = torch.nn.functional.softmax(output, dim=1)[:,1]  # Probability for class 1\n",
    "            true_labels.extend(target.cpu().numpy())\n",
    "            predictions.extend(pred.cpu().view_as(target).numpy())\n",
    "            probs.extend(prob.cpu().numpy())\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(true_labels, predictions),\n",
    "        'f1': f1_score(true_labels, predictions, average='weighted'),\n",
    "        'precision': precision_score(true_labels, predictions, average='weighted', zero_division=0),\n",
    "        'recall': recall_score(true_labels, predictions, average='weighted', zero_division=0),\n",
    "        'roc_auc_score': roc_auc_score(true_labels, probs) if len(np.unique(true_labels)) > 1 else 0,\n",
    "        'cross_entropy_loss': np.mean(losses),\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def evaluate_model(model, x_test, y_test, batch_size, criterion):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test dataset and prints out a comprehensive set of performance metrics.\n",
    "    \n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The neural network model to evaluate.\n",
    "        x_test (Tensor): Test dataset features.\n",
    "        y_test (Tensor): Test dataset labels.\n",
    "        batch_size (int): Batch size for data loading.\n",
    "        criterion (torch.nn.Module): Loss function used for the model.\n",
    "    \"\"\"\n",
    "    test_data = TensorDataset(x_test, y_test.long())\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "    \n",
    "    metrics = compute_metrics(test_loader, model, criterion)\n",
    "    \n",
    "    # Display the metrics\n",
    "    print(\"Test Metrics:\")\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        if metric_name == 'confusion_matrix':\n",
    "            print(f\"{metric_name}:\\n{metric_value}\\n\")\n",
    "        else:\n",
    "            print(f\"{metric_name}: {metric_value:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Assuming criterion is defined (e.g., nn.CrossEntropyLoss())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Example of how to use the evaluate_model function:\n",
    "# model = Net()  # Assume Net is defined elsewhere and is your trained model\n",
    "metrics = evaluate_model(model, x_test, y_test, BATCH_SIZE, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
