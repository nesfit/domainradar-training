{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 22:48:07.809457: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm \n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils.preprocess import NDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 22:48:11,322 - utils.preprocess - INFO - Benign dataset path: ../feature-extraction/floor/benign_2312.parquet\n",
      "2024-05-24 22:48:11,326 - utils.preprocess - INFO - Malign dataset path: ../feature-extraction/floor/misp_2402.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malign dataset path: ../feature-extraction/floor/misp_2402.parquet\n",
      "Benign dataset path: ../feature-extraction/floor/benign_2312.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 22:48:12,362 - utils.preprocess - INFO - Number of records in benign dataset: 462192\n",
      "2024-05-24 22:48:12,366 - utils.preprocess - INFO - Number of records in malign dataset: 110311\n",
      "2024-05-24 22:48:13,220 - utils.preprocess - INFO - Total percentage of missing values in benign dataset: 0.19%\n",
      "2024-05-24 22:48:13,227 - utils.preprocess - INFO - Total percentage of missing values in malign dataset: 0.33%\n",
      "2024-05-24 22:48:14,903 - utils.preprocess - INFO - Decision tree model saved to models/malware_decision_tree_model.joblib\n",
      "2024-05-24 22:48:14,990 - utils.preprocess - INFO - New feature 'dtree_prob' created from decision tree predictions.\n",
      "2024-05-24 22:48:15,091 - utils.preprocess - INFO - Decision Tree Train Accuracy: 0.95\n",
      "2024-05-24 22:48:15,093 - utils.preprocess - INFO - Decision Tree Test Accuracy: 0.92\n",
      "2024-05-24 22:48:17,330 - utils.preprocess - INFO - Decision Tree Cross-Validation Scores: [0.91448334 0.91553134 0.91478881]\n",
      "2024-05-24 22:48:17,335 - utils.preprocess - INFO - Generated class map: {'misp_2310:phishing': 1, 'benign_2312:unknown': 0, 'phishing_since_2402:phishing': 1}\n",
      "2024-05-24 22:48:17,576 - utils.preprocess - INFO - Outliers thresholds saved to models/outliers.joblib\n",
      "2024-05-24 22:48:17,605 - utils.preprocess - INFO - Outliers removed from dns_A_count: 46 rows\n",
      "2024-05-24 22:48:17,618 - utils.preprocess - INFO - Outliers removed from dns_AAAA_count: 52 rows\n",
      "2024-05-24 22:48:17,635 - utils.preprocess - INFO - Outliers removed from dns_MX_count: 1 rows\n",
      "2024-05-24 22:48:17,650 - utils.preprocess - INFO - Outliers removed from dns_NS_count: 1 rows\n",
      "2024-05-24 22:48:17,664 - utils.preprocess - INFO - Outliers removed from dns_TXT_count: 32 rows\n",
      "2024-05-24 22:48:17,701 - utils.preprocess - INFO - Outliers removed from dns_zone_level: 68 rows\n",
      "2024-05-24 22:48:17,718 - utils.preprocess - INFO - Outliers removed from dns_zone_digit_count: 33 rows\n",
      "2024-05-24 22:48:17,769 - utils.preprocess - INFO - Outliers removed from dns_ttl_avg: 112 rows\n",
      "2024-05-24 22:48:17,833 - utils.preprocess - INFO - Outliers removed from dns_soa_primary_ns_digit_count: 6 rows\n",
      "2024-05-24 22:48:17,875 - utils.preprocess - INFO - Outliers removed from dns_soa_email_digit_count: 36 rows\n",
      "2024-05-24 22:48:17,908 - utils.preprocess - INFO - Outliers removed from dns_soa_refresh: 4 rows\n",
      "2024-05-24 22:48:17,921 - utils.preprocess - INFO - Outliers removed from dns_soa_retry: 1 rows\n",
      "2024-05-24 22:48:17,934 - utils.preprocess - INFO - Outliers removed from dns_soa_expire: 2 rows\n",
      "2024-05-24 22:48:17,997 - utils.preprocess - INFO - Outliers removed from dns_txt_external_verification_score: 29 rows\n",
      "2024-05-24 22:48:18,031 - utils.preprocess - INFO - Outliers removed from dns_txt_dmarc_exists: 74 rows\n",
      "2024-05-24 22:48:18,049 - utils.preprocess - INFO - Outliers removed from ip_count: 3 rows\n",
      "2024-05-24 22:48:18,064 - utils.preprocess - INFO - Outliers removed from ip_mean_average_rtt: 1 rows\n",
      "2024-05-24 22:48:18,141 - utils.preprocess - INFO - Outliers removed from tls_chain_len: 1 rows\n",
      "2024-05-24 22:48:18,200 - utils.preprocess - INFO - Outliers removed from tls_root_cert_validity_len: 12 rows\n",
      "2024-05-24 22:48:18,217 - utils.preprocess - INFO - Outliers removed from tls_leaf_cert_validity_len: 20 rows\n",
      "2024-05-24 22:48:18,394 - utils.preprocess - INFO - Outliers removed from tls_subject_count: 94 rows\n",
      "2024-05-24 22:48:18,439 - utils.preprocess - INFO - Outliers removed from tls_unique_SLD_count: 35 rows\n",
      "2024-05-24 22:48:18,468 - utils.preprocess - INFO - Outliers removed from lex_name_len: 1 rows\n",
      "2024-05-24 22:48:18,495 - utils.preprocess - INFO - Outliers removed from lex_phishing_keyword_count: 2 rows\n",
      "2024-05-24 22:48:18,510 - utils.preprocess - INFO - Outliers removed from lex_benign_keyword_count: 1 rows\n",
      "2024-05-24 22:48:18,526 - utils.preprocess - INFO - Outliers removed from lex_consecutive_chars: 5 rows\n",
      "2024-05-24 22:48:18,542 - utils.preprocess - INFO - Outliers removed from lex_tld_len: 1 rows\n",
      "2024-05-24 22:48:18,577 - utils.preprocess - INFO - Outliers removed from lex_sld_len: 3 rows\n",
      "2024-05-24 22:48:18,599 - utils.preprocess - INFO - Outliers removed from lex_sld_digit_count: 63 rows\n",
      "2024-05-24 22:48:18,612 - utils.preprocess - INFO - Outliers removed from lex_sld_digit_ratio: 70 rows\n",
      "2024-05-24 22:48:18,628 - utils.preprocess - INFO - Outliers removed from lex_sld_phishing_keyword_count: 5 rows\n",
      "2024-05-24 22:48:18,657 - utils.preprocess - INFO - Outliers removed from lex_sld_consonant_count: 1 rows\n",
      "2024-05-24 22:48:18,727 - utils.preprocess - INFO - Outliers removed from lex_sld_non_alphanum_count: 78 rows\n",
      "2024-05-24 22:48:18,740 - utils.preprocess - INFO - Outliers removed from lex_sld_non_alphanum_ratio: 21 rows\n",
      "2024-05-24 22:48:18,805 - utils.preprocess - INFO - Outliers removed from lex_www_flag: 310 rows\n",
      "2024-05-24 22:48:18,819 - utils.preprocess - INFO - Outliers removed from lex_sub_max_consonant_len: 14 rows\n",
      "2024-05-24 22:48:18,843 - utils.preprocess - INFO - Outliers removed from lex_sub_digit_count: 28 rows\n",
      "2024-05-24 22:48:18,913 - utils.preprocess - INFO - Outliers removed from lex_sub_non_alphanum_count: 13 rows\n",
      "2024-05-24 22:48:18,983 - utils.preprocess - INFO - Outliers removed from lex_phishing_tetragram_matches: 3 rows\n",
      "2024-05-24 22:48:19,051 - utils.preprocess - INFO - Outliers removed from lex_malware_tetragram_matches: 4 rows\n",
      "2024-05-24 22:48:19,085 - utils.preprocess - INFO - Outliers removed from lex_dga_trigram_matches: 3 rows\n",
      "2024-05-24 22:48:19,110 - utils.preprocess - INFO - Outliers removed from lex_dga_tetragram_matches: 7 rows\n",
      "2024-05-24 22:48:19,200 - utils.preprocess - INFO - Outliers removed from lex_ipv4_in_domain: 60 rows\n",
      "2024-05-24 22:48:19,215 - utils.preprocess - INFO - Outliers removed from lex_has_trusted_suffix: 19 rows\n",
      "2024-05-24 22:48:19,229 - utils.preprocess - INFO - Outliers removed from lex_has_wellknown_suffix: 39 rows\n",
      "2024-05-24 22:48:19,244 - utils.preprocess - INFO - Outliers removed from lex_has_cdn_suffix: 6 rows\n",
      "2024-05-24 22:48:19,259 - utils.preprocess - INFO - Outliers removed from lex_has_vps_suffix: 1 rows\n",
      "2024-05-24 22:48:19,273 - utils.preprocess - INFO - Outliers removed from lex_has_img_suffix: 4 rows\n",
      "2024-05-24 22:48:19,328 - utils.preprocess - INFO - Outliers removed from geo_lat_stdev: 1 rows\n",
      "2024-05-24 22:48:19,465 - utils.preprocess - INFO - Outliers removed from geo_countries_hash: 42 rows\n",
      "2024-05-24 22:48:19,480 - utils.preprocess - INFO - Outliers removed from rdap_registration_period: 1 rows\n",
      "2024-05-24 22:48:19,503 - utils.preprocess - INFO - Outliers removed from rdap_time_from_last_change: 59 rows\n",
      "2024-05-24 22:48:19,575 - utils.preprocess - INFO - Outliers removed from rdap_registrant_name_len: 2 rows\n",
      "2024-05-24 22:48:19,598 - utils.preprocess - INFO - Outliers removed from rdap_admin_name_len: 118 rows\n",
      "2024-05-24 22:48:19,612 - utils.preprocess - INFO - Outliers removed from rdap_admin_name_entropy: 117 rows\n",
      "2024-05-24 22:48:19,625 - utils.preprocess - INFO - Outliers removed from rdap_admin_email_len: 23 rows\n",
      "2024-05-24 22:48:19,707 - utils.preprocess - INFO - Outliers removed from rdap_ip_avg_admin_name_len: 13 rows\n",
      "2024-05-24 22:48:19,749 - utils.preprocess - INFO - Completed outlier removal.\n",
      "2024-05-24 22:48:19,907 - utils.preprocess - INFO - Applying MinMaxScaler + Sigmoid scaling to the features.\n",
      "2024-05-24 22:48:20,052 - utils.preprocess - INFO - Scaler saved to models/scaler.joblib\n",
      "2024-05-24 22:48:20,056 - utils.preprocess - INFO - Scaling applied to the features\n",
      "\n",
      "2024-05-24 22:48:20,650 - utils.preprocess - INFO - Modified combined dataset saved to modified_dataset.parquet\n",
      "2024-05-24 22:48:20,655 - utils.preprocess - INFO - Head of modified combined dataset:\n",
      "2024-05-24 22:48:20,660 - utils.preprocess - INFO -        dns_has_dnskey  dns_A_count  dns_AAAA_count  dns_MX_count  \\\n",
      "0            0.731059     0.562177         0.58257      0.500000   \n",
      "1            0.500000     0.531209         0.54157      0.541570   \n",
      "2            0.500000     0.500000         0.50000      0.500000   \n",
      "3            0.500000     0.531209         0.50000      0.500000   \n",
      "4            0.500000     0.531209         0.50000      0.541570   \n",
      "...               ...          ...             ...           ...   \n",
      "28618        0.500000     0.531209         0.50000      0.500000   \n",
      "28619        0.731059     0.562177         0.58257      0.520821   \n",
      "28621        0.500000     0.531209         0.54157      0.520821   \n",
      "28622        0.731059     0.500000         0.50000      0.500000   \n",
      "28623        0.731059     0.562177         0.58257      0.520821   \n",
      "\n",
      "       dns_NS_count  dns_TXT_count  dns_SOA_count  dns_CNAME_count  \\\n",
      "0          0.500000       0.500000       0.500000              0.5   \n",
      "1          0.541570       0.517850       0.731059              0.5   \n",
      "2          0.500000       0.500000       0.500000              0.5   \n",
      "3          0.500000       0.500000       0.500000              0.5   \n",
      "4          0.541570       0.500000       0.731059              0.5   \n",
      "...             ...            ...            ...              ...   \n",
      "28618      0.541570       0.500000       0.731059              0.5   \n",
      "28619      0.541570       0.535654       0.731059              0.5   \n",
      "28621      0.562177       0.500000       0.731059              0.5   \n",
      "28622      0.500000       0.500000       0.500000              0.5   \n",
      "28623      0.541570       0.517850       0.731059              0.5   \n",
      "\n",
      "       dns_zone_level  dns_zone_digit_count  ...  rdap_ip_v6_count  \\\n",
      "0                 0.5              0.500000  ...          0.524979   \n",
      "1                 0.5              0.500000  ...          0.512497   \n",
      "2                 0.5              0.500000  ...          0.500000   \n",
      "3                 0.5              0.500000  ...          0.500000   \n",
      "4                 0.5              0.592667  ...          0.500000   \n",
      "...               ...                   ...  ...               ...   \n",
      "28618             0.5              0.500000  ...          0.524979   \n",
      "28619             0.5              0.500000  ...          0.598688   \n",
      "28621             0.5              0.500000  ...          0.549834   \n",
      "28622             0.5              0.500000  ...          0.500000   \n",
      "28623             0.5              0.500000  ...          0.598688   \n",
      "\n",
      "       rdap_ip_shortest_v4_prefix_len  rdap_ip_longest_v4_prefix_len  \\\n",
      "0                            0.592667                       0.600188   \n",
      "1                            0.651355                       0.651355   \n",
      "2                            0.500000                       0.500000   \n",
      "3                            0.679179                       0.679179   \n",
      "4                            0.672332                       0.679179   \n",
      "...                               ...                            ...   \n",
      "28618                        0.622459                       0.651355   \n",
      "28619                        0.600188                       0.665411   \n",
      "28621                        0.629775                       0.679179   \n",
      "28622                        0.500000                       0.500000   \n",
      "28623                        0.592667                       0.665411   \n",
      "\n",
      "       rdap_ip_shortest_v6_prefix_len  rdap_ip_longest_v6_prefix_len  \\\n",
      "0                            0.622459                       0.622459   \n",
      "1                            0.622459                       0.622459   \n",
      "2                            0.500000                       0.500000   \n",
      "3                            0.500000                       0.500000   \n",
      "4                            0.500000                       0.500000   \n",
      "...                               ...                            ...   \n",
      "28618                        0.577495                       0.577495   \n",
      "28619                        0.622459                       0.622459   \n",
      "28621                        0.626124                       0.724870   \n",
      "28622                        0.500000                       0.500000   \n",
      "28623                        0.622459                       0.622459   \n",
      "\n",
      "       rdap_ip_avg_admin_name_len  rdap_ip_avg_admin_name_entropy  \\\n",
      "0                        0.517117                        0.706612   \n",
      "1                        0.537600                        0.644574   \n",
      "2                        0.500000                        0.500000   \n",
      "3                        0.607867                        0.556810   \n",
      "4                        0.547799                        0.605088   \n",
      "...                           ...                             ...   \n",
      "28618                    0.573438                        0.587695   \n",
      "28619                    0.551190                        0.642100   \n",
      "28621                    0.565826                        0.600059   \n",
      "28622                    0.500000                        0.500000   \n",
      "28623                    0.561773                        0.619417   \n",
      "\n",
      "       rdap_ip_avg_admin_email_len  rdap_ip_avg_admin_email_entropy  \\\n",
      "0                         0.592667                         0.652733   \n",
      "1                         0.602685                         0.638725   \n",
      "2                         0.500000                         0.500000   \n",
      "3                         0.602685                         0.651021   \n",
      "4                         0.572404                         0.666944   \n",
      "...                            ...                              ...   \n",
      "28618                     0.579527                         0.661979   \n",
      "28619                     0.560970                         0.599616   \n",
      "28621                     0.567866                         0.629390   \n",
      "28622                     0.500000                         0.500000   \n",
      "28623                     0.581248                         0.600662   \n",
      "\n",
      "       dtree_prob  \n",
      "0        0.643574  \n",
      "1        0.500000  \n",
      "2        0.500000  \n",
      "3        0.500000  \n",
      "4        0.500000  \n",
      "...           ...  \n",
      "28618    0.731059  \n",
      "28619    0.500000  \n",
      "28621    0.500000  \n",
      "28622    0.500000  \n",
      "28623    0.500000  \n",
      "\n",
      "[26824 rows x 177 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Subset:\n",
      "Name: dataset_../feature-extraction/floor/benign2312_../feature-extraction/floor/misp2402_2024-05-24.parquet\n",
      "Features:\n",
      "   Feature_0  Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  \\\n",
      "0        0.5   0.531209        0.5   0.500000   0.582570   0.517850   \n",
      "1        0.5   0.531209        0.5   0.520821   0.562177   0.570947   \n",
      "2        0.5   0.531209        0.5   0.500000   0.500000   0.500000   \n",
      "3        0.5   0.531209        0.5   0.500000   0.500000   0.500000   \n",
      "4        0.5   0.531209        0.5   0.520821   0.541570   0.535654   \n",
      "5        0.5   0.562177        0.5   0.500000   0.541570   0.500000   \n",
      "6        0.5   0.500000        0.5   0.500000   0.500000   0.500000   \n",
      "7        0.5   0.622459        0.5   0.500000   0.500000   0.500000   \n",
      "8        0.5   0.531209        0.5   0.541570   0.562177   0.500000   \n",
      "9        0.5   0.531209        0.5   0.520821   0.562177   0.517850   \n",
      "\n",
      "   Feature_6  Feature_7  Feature_8  Feature_9  ...  Feature_167  Feature_168  \\\n",
      "0   0.731059        0.5   0.500000   0.500000  ...     0.500000     0.600188   \n",
      "1   0.731059        0.5   0.500000   0.500000  ...     0.537430     0.622459   \n",
      "2   0.500000        0.5   0.500000   0.500000  ...     0.500000     0.600188   \n",
      "3   0.500000        0.5   0.500000   0.500000  ...     0.500000     0.629775   \n",
      "4   0.731059        0.5   0.500000   0.500000  ...     0.574443     0.600188   \n",
      "5   0.731059        0.5   0.622459   0.562177  ...     0.500000     0.607663   \n",
      "6   0.500000        0.5   0.500000   0.562177  ...     0.500000     0.500000   \n",
      "7   0.500000        0.5   0.500000   0.500000  ...     0.500000     0.629775   \n",
      "8   0.731059        0.5   0.500000   0.500000  ...     0.622459     0.629775   \n",
      "9   0.731059        0.5   0.500000   0.500000  ...     0.512497     0.629775   \n",
      "\n",
      "   Feature_169  Feature_170  Feature_171  Feature_172  Feature_173  \\\n",
      "0     0.699254     0.500000     0.500000     0.577454     0.592034   \n",
      "1     0.679179     0.622459     0.731059     0.551190     0.614998   \n",
      "2     0.600188     0.500000     0.500000     0.534193     0.634845   \n",
      "3     0.629775     0.500000     0.500000     0.561333     0.596705   \n",
      "4     0.651355     0.622459     0.622459     0.542050     0.642954   \n",
      "5     0.629775     0.500000     0.500000     0.564704     0.592905   \n",
      "6     0.500000     0.500000     0.500000     0.500000     0.500000   \n",
      "7     0.629775     0.500000     0.500000     0.544403     0.615758   \n",
      "8     0.679179     0.611382     0.626124     0.542704     0.624461   \n",
      "9     0.629775     0.622459     0.622459     0.534193     0.544666   \n",
      "\n",
      "   Feature_174  Feature_175  Feature_176  \n",
      "0     0.618535     0.624702     0.500000  \n",
      "1     0.532506     0.564447     0.500000  \n",
      "2     0.617551     0.622605     0.714616  \n",
      "3     0.582570     0.672696     0.500000  \n",
      "4     0.564542     0.607247     0.500000  \n",
      "5     0.597686     0.639006     0.500000  \n",
      "6     0.500000     0.500000     0.500000  \n",
      "7     0.617551     0.616940     0.500000  \n",
      "8     0.591409     0.658448     0.500000  \n",
      "9     0.553183     0.572459     0.500000  \n",
      "\n",
      "[10 rows x 177 columns]\n",
      "Labels:\n",
      "   Label\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    1.0\n",
      "3    0.0\n",
      "4    0.0\n",
      "5    0.0\n",
      "6    0.0\n",
      "7    0.0\n",
      "8    0.0\n",
      "9    0.0\n",
      "Dimension: 177\n",
      "Index(['dns_has_dnskey', 'dns_A_count', 'dns_AAAA_count', 'dns_MX_count',\n",
      "       'dns_NS_count', 'dns_TXT_count', 'dns_SOA_count', 'dns_CNAME_count',\n",
      "       'dns_zone_level', 'dns_zone_digit_count',\n",
      "       ...\n",
      "       'rdap_ip_v6_count', 'rdap_ip_shortest_v4_prefix_len',\n",
      "       'rdap_ip_longest_v4_prefix_len', 'rdap_ip_shortest_v6_prefix_len',\n",
      "       'rdap_ip_longest_v6_prefix_len', 'rdap_ip_avg_admin_name_len',\n",
      "       'rdap_ip_avg_admin_name_entropy', 'rdap_ip_avg_admin_email_len',\n",
      "       'rdap_ip_avg_admin_email_entropy', 'dtree_prob'],\n",
      "      dtype='object', length=177)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 15\n",
    "\n",
    "\n",
    "#The whole preprocessing step happens here\n",
    "#Missing values set to -1\n",
    "#Outliers are removed\n",
    "#Encoding of categorical variables\n",
    "#Min-Max scaling, sigmoid transformation (only if cnn is used)\n",
    "input_data = {\n",
    "    'benign': '../feature-extraction/floor/benign_2312.parquet',\n",
    "    'malign': '../feature-extraction/floor/misp_2402.parquet'\n",
    "}\n",
    "\n",
    "dataset = NDF(\"cnn\", True, input_data=input_data, one_line_processing=False)\n",
    "print(dataset['feature_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smote Class Imbalance Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New class distribution after SMOTE:\n",
      "Class 0.0: 17427\n",
      "Class 1.0: 17427\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#imprt SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.array(dataset['features']), np.array(dataset['labels']), test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train_smote, y_train_smote = smote.fit_resample(x_train, y_train)\n",
    "\n",
    "# Check the new class distribution\n",
    "new_label_counts = Counter(y_train_smote)\n",
    "print(\"New class distribution after SMOTE:\")\n",
    "for label, count in new_label_counts.items():\n",
    "    print(f\"Class {label}: {count}\")\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "x_train = torch.tensor(x_train_smote, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)  # Convert x_test to tensor\n",
    "y_train = torch.tensor(y_train_smote, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long) \n",
    "feature_size = x_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# Function to calculate the next perfect square greater than a given number\n",
    "def next_perfect_square(n):\n",
    "    next_square = math.ceil(n**0.5)**2\n",
    "    return next_square\n",
    "\n",
    "feature_size = x_train.shape[1]\n",
    "desired_size = next_perfect_square(feature_size)\n",
    "side_size = int(desired_size ** 0.5)\n",
    "\n",
    "# Calculate padding required to achieve the desired size\n",
    "padding = desired_size - feature_size\n",
    "\n",
    "# Applying dynamic padding\n",
    "if padding > 0:\n",
    "    x_train_padded = F.pad(x_train, (0, padding), 'constant', 0)\n",
    "    x_test_padded = F.pad(x_test, (0, padding), 'constant', 0)\n",
    "else:\n",
    "    x_train_padded = x_train\n",
    "    x_test_padded = x_test\n",
    "\n",
    "# Reshape the data to the new dynamically calculated square shape\n",
    "x_train = x_train_padded.view(-1, 1, side_size, side_size)\n",
    "x_test = x_test_padded.view(-1, 1, side_size, side_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, side_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Adjust the size calculation based on the number of convolutional layers\n",
    "        self.fc1 = nn.Linear(128 * (side_size-6)**2, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 128)\n",
    "        self.fc4 = nn.Linear(128, 2)\n",
    "        \n",
    "        # Optionally use dropout\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        \n",
    "        print(\"CNN model created\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout1(x)  # Dropout applied after flattening\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)  # Dropout applied after first fully connected layer\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x) # No softmax here, as CrossEntropyLoss applies LogSoftmax internally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model's training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model created\n",
      "Epoch 1/3 - Loss: 0.1125, Accuracy: 0.9731, F1 Score: 0.9725\n",
      "Epoch 2/3 - Loss: 0.0750, Accuracy: 0.9798, F1 Score: 0.9796\n",
      "Epoch 3/3 - Loss: 0.0666, Accuracy: 0.9838, F1 Score: 0.9838\n",
      "Model training complete and saved.\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 0.000238\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 15\n",
    "\n",
    "model = Net(side_size).to(device)  # Classic fully connected model\n",
    "\n",
    "\n",
    "#CANNOT RETURN SOFT MAX AS THE LOSS FUNCTION IS CROSS ENTROPY\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_data = TensorDataset(x_train, y_train.long())\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Function to compute accuracy and F1 score\n",
    "def compute_metrics(data_loader, model):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            data, target = data.to(device), target.to(device)  # Move data to the device\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            true_labels.extend(target.cpu().tolist())  # Move data back to CPU for scoring\n",
    "            predictions.extend(pred.view_as(target).cpu().tolist())  # Move data back to CPU\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    return accuracy, f1\n",
    "\n",
    "epoch_losses = []\n",
    "epoch_accuracies = []\n",
    "epoch_f1s = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.to(device), target.to(device)  # Move data to the device\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Compute average loss\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    epoch_losses.append(avg_loss)\n",
    "\n",
    "    # Evaluate model and store metrics\n",
    "    train_accuracy, train_f1 = compute_metrics(train_loader, model)\n",
    "    epoch_accuracies.append(train_accuracy)\n",
    "    epoch_f1s.append(train_f1)\n",
    "\n",
    "    # Enhanced logging\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {avg_loss:.4f}, Accuracy: {train_accuracy:.4f}, F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'models/phishing_cnn_model_state_dict.pth')\n",
    "print(\"Model training complete and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics:\n",
      "accuracy: 0.9793\n",
      "f1: 0.9794\n",
      "precision: 0.9795\n",
      "recall: 0.9793\n",
      "roc_auc_score: 0.9903\n",
      "cross_entropy_loss: 0.0765\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def compute_metrics(data_loader, model, criterion):\n",
    "    \"\"\"\n",
    "    Computes a wide range of performance metrics for the given model evaluated on the provided DataLoader.\n",
    "    \n",
    "    Parameters:\n",
    "        data_loader (DataLoader): DataLoader for evaluation data.\n",
    "        model (torch.nn.Module): The neural network model to evaluate.\n",
    "        criterion (torch.nn.Module): Loss function used for the model.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing various performance metrics.\n",
    "    \"\"\"\n",
    "    model.eval()  # Switch model to evaluation mode\n",
    "    true_labels, predictions, probs, losses = [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            prob = torch.nn.functional.softmax(output, dim=1)[:,1]  # Probability for class 1\n",
    "            true_labels.extend(target.cpu().numpy())\n",
    "            predictions.extend(pred.cpu().view_as(target).numpy())\n",
    "            probs.extend(prob.cpu().numpy())\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    # Compute metrics\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(true_labels, predictions),\n",
    "        'f1': f1_score(true_labels, predictions, average='weighted'),\n",
    "        'precision': precision_score(true_labels, predictions, average='weighted', zero_division=0),\n",
    "        'recall': recall_score(true_labels, predictions, average='weighted', zero_division=0),\n",
    "        'roc_auc_score': roc_auc_score(true_labels, probs) if len(np.unique(true_labels)) > 1 else 0,\n",
    "        'cross_entropy_loss': np.mean(losses),\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def evaluate_model(model, x_test, y_test, batch_size, criterion):\n",
    "    \"\"\"\n",
    "    Evaluates the model on the test dataset and prints out a comprehensive set of performance metrics.\n",
    "    \n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The neural network model to evaluate.\n",
    "        x_test (Tensor): Test dataset features.\n",
    "        y_test (Tensor): Test dataset labels.\n",
    "        batch_size (int): Batch size for data loading.\n",
    "        criterion (torch.nn.Module): Loss function used for the model.\n",
    "    \"\"\"\n",
    "    test_data = TensorDataset(x_test, y_test.long())\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "    \n",
    "    metrics = compute_metrics(test_loader, model, criterion)\n",
    "    \n",
    "    # Display the metrics\n",
    "    print(\"Test Metrics:\")\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        if metric_name == 'confusion_matrix':\n",
    "            print(f\"{metric_name}:\\n{metric_value}\\n\")\n",
    "        else:\n",
    "            print(f\"{metric_name}: {metric_value:.4f}\")\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Assuming criterion is defined (e.g., nn.CrossEntropyLoss())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Example of how to use the evaluate_model function:\n",
    "# model = Net()  # Assume Net is defined elsewhere and is your trained model\n",
    "metrics = evaluate_model(model, x_test, y_test, BATCH_SIZE, criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
